{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Model & Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Load Packages and Datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF, TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "# Load pre-processed train and test set from EDA notebook\n",
    "train_df = pd.read_json('./../data/preprocess_train.json')\n",
    "test_df = pd.read_json('./../data/preprocess_test.json')\n",
    "\n",
    "raw_train_df = pd.read_json('./../data/train.json')\n",
    "raw_test_df = pd.read_json('./../data/test.json')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Model Building\n",
    "\n",
    "### 2.1 Topic Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/jvo/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample results from training data:\n",
      "                                           full_text sentiment\n",
      "0  Design Thinking for innovation reflexion-Avril...  positive\n",
      "1  Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...  positive\n",
      "2  Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...  positive\n",
      "3  Design Thinking for Innovation\\n\\nSindy Samaca...  positive\n",
      "4  Assignment:  Visualization Reflection  Submitt...  positive\n",
      "\n",
      "Sample results from test data:\n",
      "                                           full_text sentiment\n",
      "0  Design Thinking for innovation reflexion-Avril...  positive\n",
      "1  Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...  positive\n",
      "2  Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...  positive\n",
      "3  Design Thinking for Innovation\\n\\nSindy Samaca...  positive\n",
      "4  Assignment:  Visualization Reflection  Submitt...  positive\n"
     ]
    }
   ],
   "source": [
    "# Sentiment analysis\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize VADER sentiment analyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define a function to perform sentiment analysis on a single piece of text\n",
    "def analyze_sentiment(text):\n",
    "    # Get sentiment scores\n",
    "    scores = sid.polarity_scores(text)\n",
    "\n",
    "    # Classify sentiment\n",
    "    if scores['compound'] >= 0.05:\n",
    "        return 'positive'\n",
    "    elif scores['compound'] <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Apply sentiment analysis to your text data\n",
    "train_df['sentiment'] = train_df['full_text'].apply(analyze_sentiment)\n",
    "test_df['sentiment'] = test_df['full_text'].apply(analyze_sentiment)\n",
    "\n",
    "# Print some sample results\n",
    "print(\"Sample results from training data:\")\n",
    "print(train_df[['full_text', 'sentiment']].head())\n",
    "\n",
    "print(\"\\nSample results from test data:\")\n",
    "print(test_df[['full_text', 'sentiment']].head())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 00\n",
      " launch (2.04)\n",
      " learning (1.69)\n",
      " team (1.22)\n",
      " product (0.97)\n",
      " customers (0.82)\n",
      "\n",
      "Topic 01\n",
      " storytelling (1.88)\n",
      " story (1.86)\n",
      " people (1.17)\n",
      " stories (1.12)\n",
      " audience (0.60)\n",
      "\n",
      "Topic 02\n",
      " mind (3.08)\n",
      " mapping (2.43)\n",
      " ideas (1.18)\n",
      " map (1.17)\n",
      " tool (0.86)\n",
      "\n",
      "Topic 03\n",
      " graphic (2.91)\n",
      " visualization (1.92)\n",
      " group (1.77)\n",
      " problem (1.66)\n",
      " straw (1.35)\n",
      "\n",
      "Topic 04\n",
      " students (9.79)\n",
      " student (2.16)\n",
      " school (2.15)\n",
      " teachers (1.55)\n",
      " class (1.37)\n"
     ]
    }
   ],
   "source": [
    "# NMF Model\n",
    "corpus_train = train_df['tokens_processed'].apply(lambda tokens: ' '.join(tokens))\n",
    "corpus_test = test_df['tokens_processed'].apply(lambda tokens: ' '.join(tokens))\n",
    "corpus = pd.concat([corpus_train, corpus_test], ignore_index=True)\n",
    "\n",
    "# TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "tfidf_X = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Count Vectorizer\n",
    "count_vectorizer = CountVectorizer(max_features=1000)\n",
    "count_X = count_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Initialize and fit NMF model\n",
    "num_topics = 5\n",
    "nmf_model = NMF(n_components=num_topics, random_state=42)\n",
    "nmf_model.fit(tfidf_X)\n",
    "\n",
    "def display_topics(model, features, no_top_words=5):\n",
    "    for topic, words in enumerate(model.components_):\n",
    "        total = words.sum()\n",
    "        largest = words.argsort()[::-1]\n",
    "        print(\"\\nTopic %02d\" % topic)\n",
    "        for i in range(0, no_top_words):\n",
    "            print(\" %s (%2.2f)\" % (features[largest[i]], abs(words[largest[i]]*100.0/total)))\n",
    "\n",
    "\n",
    "display_topics(nmf_model, tfidf_vectorizer.get_feature_names_out())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 00\n",
      " tool (0.64)\n",
      " team (0.59)\n",
      " mind (0.59)\n",
      " learning (0.50)\n",
      " design (0.50)\n",
      "\n",
      "Topic 01\n",
      " story (42.47)\n",
      " storytelling (41.01)\n",
      " stories (27.16)\n",
      " people (18.62)\n",
      " telling (12.54)\n",
      "\n",
      "Topic 02\n",
      " mind (85.48)\n",
      " mapping (66.68)\n",
      " map (33.79)\n",
      " graphic (26.18)\n",
      " ideas (25.05)\n",
      "\n",
      "Topic 03\n",
      " graphic (18.38)\n",
      " visualization (9.30)\n",
      " group (8.78)\n",
      " straw (8.70)\n",
      " man (7.74)\n",
      "\n",
      "Topic 04\n",
      " students (56.99)\n",
      " learning (19.50)\n",
      " launch (14.99)\n",
      " school (12.87)\n",
      " student (12.75)\n"
     ]
    }
   ],
   "source": [
    "#LSA Model\n",
    "lsa_model = TruncatedSVD(n_components=num_topics, random_state=42)\n",
    "lsa_model.fit(tfidf_X)\n",
    "\n",
    "# Display topics\n",
    "display_topics(lsa_model, tfidf_vectorizer.get_feature_names_out())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 00\n",
      " storytelling (1.91)\n",
      " story (1.83)\n",
      " people (1.80)\n",
      " tool (1.07)\n",
      " one (0.94)\n",
      "\n",
      "Topic 01\n",
      " visualization (2.11)\n",
      " process (1.60)\n",
      " tool (1.38)\n",
      " team (1.35)\n",
      " would (1.04)\n",
      "\n",
      "Topic 02\n",
      " mind (4.53)\n",
      " mapping (3.24)\n",
      " ideas (2.01)\n",
      " tool (1.89)\n",
      " design (1.82)\n",
      "\n",
      "Topic 03\n",
      " group (3.27)\n",
      " problem (2.96)\n",
      " graphic (2.61)\n",
      " insights (2.05)\n",
      " identify (1.74)\n",
      "\n",
      "Topic 04\n",
      " learning (2.32)\n",
      " launch (2.17)\n",
      " team (1.66)\n",
      " product (1.35)\n",
      " customers (1.24)\n"
     ]
    }
   ],
   "source": [
    "# LDA Model\n",
    "lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "lda_model.fit(count_X)\n",
    "\n",
    "# Display topics\n",
    "display_topics(lda_model, count_vectorizer.get_feature_names_out())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 Random Forest Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "# Convert list of tokens back to strings\n",
    "train_df['tokens_joined'] = train_df['tokens_processed'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "# Extract features and labels\n",
    "X = train_df['tokens_joined']\n",
    "y = train_df['labels_processed']\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_bin = mlb.fit_transform(y)\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X_tfidf = tfidf.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_tfidf, y_bin, test_size=0.2, random_state=599)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.00      0.00      0.00        12\n",
      "           2       1.00      0.01      0.01       183\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00       169\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       1.00      1.00      1.00      1362\n",
      "\n",
      "   micro avg       1.00      0.78      0.88      1744\n",
      "   macro avg       0.15      0.08      0.08      1744\n",
      "weighted avg       0.89      0.78      0.78      1744\n",
      " samples avg       1.00      0.91      0.93      1744\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=599)\n",
    "\n",
    "# Train the classifier\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = rf_classifier.predict(X_valid)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_valid, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
