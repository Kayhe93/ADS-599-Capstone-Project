{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Packages and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF, TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from presidio_analyzer import AnalyzerEngine, EntityRecognizer, PatternRecognizer, Pattern, RecognizerResult\n",
    "from presidio_analyzer.context_aware_enhancers import LemmaContextAwareEnhancer\n",
    "from presidio_analyzer.nlp_engine import NlpArtifacts, NlpEngineProvider\n",
    "from presidio_analyzer.recognizer_registry import RecognizerRegistry\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from presidio_analyzer.predefined_recognizers import EmailRecognizer, UrlRecognizer, PhoneRecognizer\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from dateutil import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'warnings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mwarnings\u001b[49m\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, category\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mSettingWithCopyWarning)\n\u001b[1;32m      2\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_columns\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.width\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1000\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'warnings' is not defined"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-processed train and test set from EDA notebook\n",
    "train_df = pd.read_json('/Users/Kayan/Desktop/ADS-599-Capstone-Project/data/preprocess_train.json')\n",
    "test_df = pd.read_json('/Users/Kayan/Desktop/ADS-599-Capstone-Project/data/preprocess_test.json')\n",
    "\n",
    "raw_train_df = pd.read_json('/Users/Kayan/Desktop/ADS-599-Capstone-Project/data/train.json')\n",
    "raw_test_df = pd.read_json('/Users/Kayan/Desktop/ADS-599-Capstone-Project/data/test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Building\n",
    "\n",
    "### 2.1 Topic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Sentiment analysis\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mnltk\u001b[49m\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvader_lexicon\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize VADER sentiment analyzer\u001b[39;00m\n\u001b[1;32m      5\u001b[0m sid \u001b[38;5;241m=\u001b[39m SentimentIntensityAnalyzer()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "# Sentiment analysis\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize VADER sentiment analyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define a function to perform sentiment analysis on a single piece of text\n",
    "def analyze_sentiment(text):\n",
    "    # Get sentiment scores\n",
    "    scores = sid.polarity_scores(text)\n",
    "\n",
    "    # Classify sentiment\n",
    "    if scores['compound'] >= 0.05:\n",
    "        return 'positive'\n",
    "    elif scores['compound'] <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Apply sentiment analysis to your text data\n",
    "train_df['sentiment'] = train_df['full_text'].apply(analyze_sentiment)\n",
    "test_df['sentiment'] = test_df['full_text'].apply(analyze_sentiment)\n",
    "\n",
    "# Print some sample results\n",
    "print(\"Sample results from training data:\")\n",
    "print(train_df[['full_text', 'sentiment']].head())\n",
    "\n",
    "print(\"\\nSample results from test data:\")\n",
    "print(test_df[['full_text', 'sentiment']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 00\n",
      " launch (2.04)\n",
      " learning (1.69)\n",
      " team (1.22)\n",
      " product (0.97)\n",
      " customers (0.82)\n",
      "\n",
      "Topic 01\n",
      " storytelling (1.88)\n",
      " story (1.86)\n",
      " people (1.17)\n",
      " stories (1.12)\n",
      " audience (0.60)\n",
      "\n",
      "Topic 02\n",
      " mind (3.08)\n",
      " mapping (2.43)\n",
      " ideas (1.18)\n",
      " map (1.17)\n",
      " tool (0.86)\n",
      "\n",
      "Topic 03\n",
      " graphic (2.91)\n",
      " visualization (1.92)\n",
      " group (1.77)\n",
      " problem (1.66)\n",
      " straw (1.35)\n",
      "\n",
      "Topic 04\n",
      " students (9.79)\n",
      " student (2.16)\n",
      " school (2.15)\n",
      " teachers (1.56)\n",
      " class (1.37)\n"
     ]
    }
   ],
   "source": [
    "# NMF Model\n",
    "corpus_train = train_df['tokens_processed'].apply(lambda tokens: ' '.join(tokens))\n",
    "corpus_test = test_df['tokens_processed'].apply(lambda tokens: ' '.join(tokens))\n",
    "corpus = pd.concat([corpus_train, corpus_test], ignore_index=True)\n",
    "\n",
    "# TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "tfidf_X = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Count Vectorizer\n",
    "count_vectorizer = CountVectorizer(max_features=1000)\n",
    "count_X = count_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Initialize and fit NMF model\n",
    "num_topics = 5\n",
    "nmf_model = NMF(n_components=num_topics, random_state=42)\n",
    "nmf_model.fit(tfidf_X)\n",
    "\n",
    "def display_topics(model, features, no_top_words=5):\n",
    "    for topic, words in enumerate(model.components_):\n",
    "        total = words.sum()\n",
    "        largest = words.argsort()[::-1]\n",
    "        print(\"\\nTopic %02d\" % topic)\n",
    "        for i in range(0, no_top_words):\n",
    "            print(\" %s (%2.2f)\" % (features[largest[i]], abs(words[largest[i]]*100.0/total)))\n",
    "\n",
    "\n",
    "display_topics(nmf_model, tfidf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 00\n",
      " tool (0.64)\n",
      " team (0.59)\n",
      " mind (0.59)\n",
      " learning (0.50)\n",
      " design (0.50)\n",
      "\n",
      "Topic 01\n",
      " story (42.47)\n",
      " storytelling (41.01)\n",
      " stories (27.16)\n",
      " people (18.62)\n",
      " telling (12.54)\n",
      "\n",
      "Topic 02\n",
      " mind (85.48)\n",
      " mapping (66.68)\n",
      " map (33.79)\n",
      " graphic (26.18)\n",
      " ideas (25.05)\n",
      "\n",
      "Topic 03\n",
      " graphic (18.38)\n",
      " visualization (9.30)\n",
      " group (8.78)\n",
      " straw (8.70)\n",
      " man (7.74)\n",
      "\n",
      "Topic 04\n",
      " students (56.99)\n",
      " learning (19.50)\n",
      " launch (14.99)\n",
      " school (12.87)\n",
      " student (12.75)\n"
     ]
    }
   ],
   "source": [
    "#LSA Model\n",
    "lsa_model = TruncatedSVD(n_components=num_topics, random_state=42)\n",
    "lsa_model.fit(tfidf_X)\n",
    "\n",
    "# Display topics\n",
    "display_topics(lsa_model, tfidf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 00\n",
      " storytelling (1.91)\n",
      " story (1.83)\n",
      " people (1.80)\n",
      " tool (1.07)\n",
      " one (0.94)\n",
      "\n",
      "Topic 01\n",
      " visualization (2.11)\n",
      " process (1.60)\n",
      " tool (1.38)\n",
      " team (1.35)\n",
      " would (1.04)\n",
      "\n",
      "Topic 02\n",
      " mind (4.53)\n",
      " mapping (3.24)\n",
      " ideas (2.01)\n",
      " tool (1.89)\n",
      " design (1.82)\n",
      "\n",
      "Topic 03\n",
      " group (3.27)\n",
      " problem (2.96)\n",
      " graphic (2.61)\n",
      " insights (2.05)\n",
      " identify (1.74)\n",
      "\n",
      "Topic 04\n",
      " learning (2.32)\n",
      " launch (2.17)\n",
      " team (1.66)\n",
      " product (1.35)\n",
      " customers (1.24)\n"
     ]
    }
   ],
   "source": [
    "# LDA Model\n",
    "lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "lda_model.fit(count_X)\n",
    "\n",
    "# Display topics\n",
    "display_topics(lda_model, count_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list of tokens back to strings\n",
    "train_df['tokens_joined'] = train_df['tokens_processed'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "# Extract features and labels\n",
    "X = train_df['tokens_joined']\n",
    "y = train_df['labels_processed']\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_bin = mlb.fit_transform(y)\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X_tfidf = tfidf.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_tfidf, y_bin, test_size=0.2, random_state=599)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.00      0.00      0.00        12\n",
      "           2       1.00      0.01      0.01       183\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00       169\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       1.00      1.00      1.00      1362\n",
      "\n",
      "   micro avg       1.00      0.78      0.88      1744\n",
      "   macro avg       0.15      0.08      0.08      1744\n",
      "weighted avg       0.89      0.78      0.78      1744\n",
      " samples avg       1.00      0.91      0.93      1744\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kayan/.pyenv/versions/3.9.6/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kayan/.pyenv/versions/3.9.6/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=599)\n",
    "\n",
    "# Train the classifier\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = rf_classifier.predict(X_valid)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 27.638978242874146 seconds\n",
      "Accuracy: 0.8531571218795888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       1.00      0.08      0.15        12\n",
      "           2       0.38      0.04      0.08       183\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.22      0.02      0.04       169\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       1.00      1.00      1.00      1362\n",
      "\n",
      "   micro avg       0.98      0.79      0.87      1744\n",
      "   macro avg       0.20      0.09      0.10      1744\n",
      "weighted avg       0.85      0.79      0.79      1744\n",
      " samples avg       0.99      0.91      0.93      1744\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kayan/.pyenv/versions/3.9.6/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kayan/.pyenv/versions/3.9.6/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "# Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the classifier\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_knn = knn_classifier.predict(X_valid)\n",
    "\n",
    "# Record end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate runtime\n",
    "runtime = end_time - start_time\n",
    "print(\"Runtime:\", runtime, \"seconds\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_valid, y_pred_knn)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_valid, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_knn = {\n",
    "    'n_neighbors': range(1, 11, 1), \n",
    "    'leaf_size': range(20, 41, 1),   \n",
    "    'p': [1, 2],                       \n",
    "    'weights': ['uniform', 'distance'],  \n",
    "    'metric': ['minkowski', 'chebyshev']  \n",
    "}\n",
    "start_time_knn = time.time()\n",
    "\n",
    "# Instantiate GridSearchCV\n",
    "grid_search = GridSearchCV(knn_classifier, param_grid_knn, cv=5, scoring='accuracy')\n",
    "\n",
    "# Perform grid search to find the best parameters\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_knn_model = KNeighborsClassifier(**best_params)\n",
    "\n",
    "# Train the model on the training data\n",
    "final_knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_knn_param = final_knn_model.predict(X_valid)\n",
    "\n",
    "end_time_knn = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "runtime_knn_param = end_time_knn - start_time_knn\n",
    "print(\"Model runtime:\", runtime_knn_param, \"seconds\")\n",
    "evaluate(y_valid, y_pred_knn_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 BERT with MS Presidio Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T19:25:23.125036Z",
     "iopub.status.busy": "2024-02-12T19:25:23.124244Z",
     "iopub.status.idle": "2024-02-12T19:25:38.764328Z",
     "shell.execute_reply": "2024-02-12T19:25:38.763278Z",
     "shell.execute_reply.started": "2024-02-12T19:25:23.124989Z"
    }
   },
   "outputs": [],
   "source": [
    "#Only using TRAIN Data and splitting in 80/20\n",
    "\n",
    "train = pd.read_json('./../data/train.json')\n",
    "#test = pd.read_json('./../data/test.json')\n",
    "\n",
    "preprocessed_train = pd.read_json('./../data/preprocess_train.json')\n",
    "#preprocessed_test = pd.read_json('./../data/preprocess_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T19:25:38.766533Z",
     "iopub.status.busy": "2024-02-12T19:25:38.766043Z",
     "iopub.status.idle": "2024-02-12T19:25:38.774817Z",
     "shell.execute_reply": "2024-02-12T19:25:38.773084Z",
     "shell.execute_reply.started": "2024-02-12T19:25:38.766489Z"
    }
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "def token_index(row):\n",
    "    tokens  = row['tokens']\n",
    "    start_ind = []\n",
    "    end_ind = []\n",
    "    prev_ind = 0\n",
    "    for tok in tokens:\n",
    "        start = prev_ind + row['full_text'][prev_ind:].index(tok)\n",
    "        end = start+len(tok)\n",
    "        start_ind.append(start)\n",
    "        end_ind.append(end)\n",
    "        prev_ind = end\n",
    "    return start_ind, end_ind\n",
    "\n",
    "def find_larger(arr, target):\n",
    "    left, right = 0, len(arr) - 1\n",
    "\n",
    "    while left <= right:\n",
    "        mid = (left + right) // 2\n",
    "\n",
    "        if arr[mid] == target:\n",
    "            return mid\n",
    "        elif arr[mid] < target:\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            right = mid - 1\n",
    "    return left\n",
    "\n",
    "def count_whitespaces(word):\n",
    "    return len(word) - len(word.rstrip())\n",
    "\n",
    "def date_check(text):\n",
    "    try:\n",
    "        parsed_date = parser.parse(text)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "\n",
    "def pii_fbeta_score(pred_df, gt_df,beta=5):\n",
    "    df = pred_df.merge(gt_df,how='outer',on=['document',\"token\"],suffixes=('_pred','_gt'))\n",
    "\n",
    "    df['cm'] = \"\"\n",
    "\n",
    "    df.loc[df.label_gt.isna(),'cm'] = \"FP\"\n",
    "    df.loc[df.label_pred.isna(),'cm'] = \"FN\"\n",
    "    df.loc[(df.label_gt.notna()) & (df.label_gt!=df.label_pred),'cm'] = \"FN\"\n",
    "\n",
    "    df.loc[(df.label_pred.notna()) & (df.label_gt.notna()) & (df.label_gt==df.label_pred),'cm'] = \"TP\"\n",
    "    \n",
    "    FP = (df['cm']==\"FP\").sum()\n",
    "    FN = (df['cm']==\"FN\").sum()\n",
    "    TP = (df['cm']==\"TP\").sum()\n",
    "    \n",
    "    precision = TP/(TP + FP)\n",
    "    recall = TP/(TP + FN)\n",
    "    f1 = precision * recall / (precision + recall)\n",
    "    \n",
    "    print(\"Precision: \" + str(precision))\n",
    "    print(\"Recall: \" + str(recall))\n",
    "    print(\"F1-Score: \" + str(f1))\n",
    "\n",
    "    s_micro = (1+(beta**2))*TP/(((1+(beta**2))*TP) + ((beta**2)*FN) + FP)\n",
    "\n",
    "    return s_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T19:25:38.928163Z",
     "iopub.status.busy": "2024-02-12T19:25:38.927231Z",
     "iopub.status.idle": "2024-02-12T19:25:38.937525Z",
     "shell.execute_reply": "2024-02-12T19:25:38.93639Z",
     "shell.execute_reply.started": "2024-02-12T19:25:38.928127Z"
    }
   },
   "outputs": [],
   "source": [
    "# Modeling\n",
    "x = pd.DataFrame(preprocessed_train)\n",
    "y = x['labels']\n",
    "x = x.drop(columns='labels')\n",
    "train_x, val_x, train_y, val_y = train_test_split(x, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T19:25:38.939833Z",
     "iopub.status.busy": "2024-02-12T19:25:38.93944Z",
     "iopub.status.idle": "2024-02-12T19:25:38.948439Z",
     "shell.execute_reply": "2024-02-12T19:25:38.9475Z",
     "shell.execute_reply.started": "2024-02-12T19:25:38.9398Z"
    }
   },
   "outputs": [],
   "source": [
    "ALLOW_LIST = []\n",
    "DENY_LIST_EMAIL = []\n",
    "DENY_LIST_ADDRESS = []\n",
    "DENY_LIST_URL = []\n",
    "DENY_LIST_NAME = []\n",
    "DENY_LIST_PHONE = []\n",
    "DENY_LIST_ID = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T19:25:38.950158Z",
     "iopub.status.busy": "2024-02-12T19:25:38.949782Z",
     "iopub.status.idle": "2024-02-12T19:25:39.800175Z",
     "shell.execute_reply": "2024-02-12T19:25:39.799021Z",
     "shell.execute_reply.started": "2024-02-12T19:25:38.950114Z"
    }
   },
   "outputs": [],
   "source": [
    "all_stopwords = list(stopwords.words())\n",
    "words = Counter()\n",
    "for doc in preprocessed_train.tokens:\n",
    "    words.update(doc)\n",
    "#for doc in preprocessed_test.tokens:\n",
    "#    words.update(doc)\n",
    "all_stopwords  += [str(w).lower() for w, i in words.items() if i > 55]\n",
    "all_stopwords = list(sorted(set(all_stopwords)))\n",
    "del words\n",
    "\n",
    "ALLOW_LIST.extend(all_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T19:25:39.802438Z",
     "iopub.status.busy": "2024-02-12T19:25:39.801495Z",
     "iopub.status.idle": "2024-02-12T19:25:39.809089Z",
     "shell.execute_reply": "2024-02-12T19:25:39.807892Z",
     "shell.execute_reply.started": "2024-02-12T19:25:39.802404Z"
    }
   },
   "outputs": [],
   "source": [
    "PHONE_ALLOW_LIST = ['phone', 'number', 'telephone', 'cell', 'cellphone',\n",
    "              'mobile', 'call', 'ph', 'tel', 'mobile', 'Email']\n",
    "URL_DENY_LIST = [\"wikipedia\", \"coursera\", \".pdf\", \".PDF\", \"article\",\n",
    "             \".png\",\".gov\", \".work\", \".ai\", \".firm\", \".arts\",\n",
    "             \".store\", \".rec\", \".biz\", \".travel\", '.ru', 'designabetterbusiness', '.tools', 'designorate',\n",
    "                       'designresearchtechniques', 'ec', '.europa', 'forbes', 'google',\n",
    "                       'ideas', 'trello', '.edu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T19:25:39.811696Z",
     "iopub.status.busy": "2024-02-12T19:25:39.811228Z",
     "iopub.status.idle": "2024-02-12T19:25:39.847128Z",
     "shell.execute_reply": "2024-02-12T19:25:39.84578Z",
     "shell.execute_reply.started": "2024-02-12T19:25:39.811639Z"
    }
   },
   "outputs": [],
   "source": [
    "#Prepping the list of datasets for PII\n",
    "DENY_LIST_NAME.extend(us_names)\n",
    "DENY_LIST_NAME.extend(nltk_female)\n",
    "DENY_LIST_NAME.extend(nltk_male)\n",
    "DENY_LIST_NAME.extend(french_dept)\n",
    "DENY_LIST_NAME.extend(french_nat)\n",
    "\n",
    "tokens = train_x['tokens'].apply(pd.Series).stack().reset_index(drop=True).tolist()\n",
    "labels = train_y.apply(pd.Series).stack().reset_index(drop=True).tolist()\n",
    "\n",
    "#tokens = train['tokens'].apply(pd.Series).stack().reset_index(drop=True).tolist()\n",
    "#labels = train['labels'].apply(pd.Series).stack().reset_index(drop=True).tolist()\n",
    "\n",
    "for i in set(labels):\n",
    "    indices = [j for j in range(len(labels)) if labels[j] == i]\n",
    "    if i == 'O':\n",
    "        ALLOW_LIST.extend([tokens[i] for i in indices])\n",
    "    if i == 'B-EMAIL':\n",
    "        DENY_LIST_EMAIL.extend([tokens[i] for i in indices])\n",
    "    elif i in ['B-STREET_ADDRESS', 'I-STREET_ADDRESS']:\n",
    "        DENY_LIST_ADDRESS.extend([tokens[i] for i in indices])\n",
    "    elif i in ['B-URL_PERSONAL', 'I-URL_PERSONAL']:\n",
    "        DENY_LIST_URL.extend([tokens[i] for i in indices])\n",
    "    elif i in ['B-NAME_STUDENT', 'I-NAME_STUDENT']:\n",
    "    #elif i in ['I-NAME_STUDENT']:\n",
    "        DENY_LIST_NAME.extend([tokens[i] for i in indices])\n",
    "    elif i in ['B-PHONE_NUM', 'I-PHONE_NUM']:\n",
    "        DENY_LIST_PHONE.extend([tokens[i] for i in indices])\n",
    "    elif i in ['B-ID_NUM', 'I-ID_NUM']:\n",
    "        DENY_LIST_ID.extend([tokens[i] for i in indices])\n",
    "    else:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T19:25:39.848726Z",
     "iopub.status.busy": "2024-02-12T19:25:39.848339Z",
     "iopub.status.idle": "2024-02-12T19:25:39.86027Z",
     "shell.execute_reply": "2024-02-12T19:25:39.85901Z",
     "shell.execute_reply.started": "2024-02-12T19:25:39.84866Z"
    }
   },
   "outputs": [],
   "source": [
    "id_regex = r'([A-Za-z]{2}[.?]:)?\\d{12,12}'\n",
    "id_pattern = Pattern(name=\"id\", regex=id_regex, score = 0.5)\n",
    "id_recognizer = PatternRecognizer(supported_entity=\"ID_CUSTOM\", patterns = [id_pattern])\n",
    "\n",
    "address_regex = r'\\b\\d+\\s+\\w+(\\s+\\w+)*\\s+((st(\\.)?)|(ave(\\.)?)|(cir(\\.)?)|(rd(\\.)?)|(blvd(\\.)?)|(ln(\\.)?)|(ct(\\.)?)|(dr(\\.)?))\\b'\n",
    "address_pattern = Pattern(name=\"address\", regex=address_regex, score=0.5)\n",
    "address_recognizer = PatternRecognizer(supported_entity=\"ADDRESS_CUSTOM\", patterns = [address_pattern], context=[\"st\", \"Apt\"])\n",
    "\n",
    "email_regex = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "email_pattern = Pattern(name=\"email address\", regex=email_regex, score=0.5)\n",
    "email_recognizer = PatternRecognizer(supported_entity=\"EMAIL_CUSTOM\", patterns = [email_pattern])\n",
    "\n",
    "url_regex = r'((https?)|(http?)|(ftp?))://\\S+|www\\.\\S+'\n",
    "url_pattern = Pattern(name=\"url\", regex=url_regex, score=0.5)\n",
    "url_recognizer = PatternRecognizer(supported_entity=\"URL_CUSTOM\", patterns = [url_pattern])\n",
    "\n",
    "phone_regex = r'^[\\+]?[(]?[0-9]{3}[)]?[-\\s\\.]?[0-9]{3}[-\\s\\.]?[0-9]{4,6}$'\n",
    "phone_pattern = Pattern(name='phone', regex=phone_regex, score=0.5)\n",
    "phone_recognizer = PatternRecognizer(supported_entity='PHONE_CUSTOM', patterns=[phone_pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T19:25:39.86229Z",
     "iopub.status.busy": "2024-02-12T19:25:39.861756Z",
     "iopub.status.idle": "2024-02-12T19:25:39.874842Z",
     "shell.execute_reply": "2024-02-12T19:25:39.87395Z",
     "shell.execute_reply.started": "2024-02-12T19:25:39.862257Z"
    }
   },
   "outputs": [],
   "source": [
    "class NumbersRecognizer(EntityRecognizer):\n",
    "\n",
    "    expected_confidence_level = 0.7  # expected confidence level for this recognizer\n",
    "\n",
    "    def load(self) -> None:\n",
    "        \"\"\"No loading is required.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def analyze(self, text: str, entities: list[str], nlp_artifacts: NlpArtifacts) -> list[RecognizerResult]:\n",
    "        \"\"\"\n",
    "        Analyzes test to find tokens which represent numbers (either 123 or One Two Three).\n",
    "        \"\"\"\n",
    "        results = []\n",
    "\n",
    "        # iterate over the spaCy tokens, and call `token.like_num`\n",
    "        for token in nlp_artifacts.tokens:\n",
    "            if token.like_num:\n",
    "                result = RecognizerResult(\n",
    "                    entity_type=\"NUMBER\",\n",
    "                    start=token.idx,\n",
    "                    end=token.idx + len(token),\n",
    "                    score=self.expected_confidence_level,\n",
    "                )\n",
    "                results.append(result)\n",
    "        return results\n",
    "\n",
    "new_numbers_recognizer = NumbersRecognizer(supported_entities=[\"NUMBER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T19:25:39.877468Z",
     "iopub.status.busy": "2024-02-12T19:25:39.877019Z",
     "iopub.status.idle": "2024-02-12T19:25:45.285305Z",
     "shell.execute_reply": "2024-02-12T19:25:45.284141Z",
     "shell.execute_reply.started": "2024-02-12T19:25:39.877433Z"
    }
   },
   "outputs": [],
   "source": [
    "configuration = {\n",
    "    \"nlp_engine_name\": \"spacy\",\n",
    "    \"models\": [{\"lang_code\": \"en\", \"model_name\": \"en_core_web_lg\"}],\n",
    "}\n",
    "provider = NlpEngineProvider(nlp_configuration=configuration)\n",
    "nlp_engine = provider.create_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T19:25:45.28829Z",
     "iopub.status.busy": "2024-02-12T19:25:45.287749Z",
     "iopub.status.idle": "2024-02-12T19:25:45.295415Z",
     "shell.execute_reply": "2024-02-12T19:25:45.294242Z",
     "shell.execute_reply.started": "2024-02-12T19:25:45.288259Z"
    }
   },
   "outputs": [],
   "source": [
    "dictionary = RecognizerRegistry()\n",
    "dictionary.load_predefined_recognizers()\n",
    "dictionary.add_recognizer(address_recognizer)\n",
    "dictionary.add_recognizer(email_recognizer)\n",
    "dictionary.add_recognizer(url_recognizer)\n",
    "dictionary.add_recognizer(phone_recognizer)\n",
    "dictionary.add_recognizer(id_recognizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T19:25:45.297395Z",
     "iopub.status.busy": "2024-02-12T19:25:45.296891Z",
     "iopub.status.idle": "2024-02-12T19:25:45.452863Z",
     "shell.execute_reply": "2024-02-12T19:25:45.451707Z",
     "shell.execute_reply.started": "2024-02-12T19:25:45.297348Z"
    }
   },
   "outputs": [],
   "source": [
    "analyzer = AnalyzerEngine(supported_languages=['en'],\n",
    "                          registry=dictionary,\n",
    "                          nlp_engine=nlp_engine,\n",
    "                          context_aware_enhancer=LemmaContextAwareEnhancer(\n",
    "                              context_similarity_factor=0.6,\n",
    "                              min_score_with_context_similarity=0.4\n",
    "                          ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T19:25:45.454975Z",
     "iopub.status.busy": "2024-02-12T19:25:45.454524Z",
     "iopub.status.idle": "2024-02-12T19:25:45.463937Z",
     "shell.execute_reply": "2024-02-12T19:25:45.462967Z",
     "shell.execute_reply.started": "2024-02-12T19:25:45.454932Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training/Testing\n",
    "preds = []\n",
    "#test = preprocessed_test\n",
    "test = val_x\n",
    "temp = test.apply(lambda x: token_index(x), axis=1)\n",
    "test['start'] = temp.apply(lambda x: x[0])\n",
    "test['end'] = temp.apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T19:25:45.550793Z",
     "iopub.status.busy": "2024-02-12T19:25:45.550414Z",
     "iopub.status.idle": "2024-02-12T19:25:47.649727Z",
     "shell.execute_reply": "2024-02-12T19:25:47.6489Z",
     "shell.execute_reply.started": "2024-02-12T19:25:45.55076Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]1702it [03:18,  8.56it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, d in enumerate(tqdm(test.iterrows())):\n",
    "    results = analyzer.analyze(text=d[1]['full_text'],\n",
    "                               entities=[\"PHONE_CUSTOM\", \"PERSON\", \"URL_CUSTOM\", \"EMAIL_ADDRESS\",\n",
    "                                         \"EMAIL_CUSTOM\", \"ADDRESS_CUSTOM\", \"US_SSN\", \"US_ITIN\",\n",
    "                                         \"US_PASSPORT\", \"US_BANK_NUMBER\", \"USERNAME\", \"ID_CUSTOM\"],\n",
    "                               allow_list=ALLOW_LIST,\n",
    "                               language='en', \n",
    "                               score_threshold=0.005)\n",
    "    pre_preds = []\n",
    "    for r in results:\n",
    "        s = find_larger(d[1]['start'], r.start)\n",
    "        end = r.end\n",
    "        word = d[1]['full_text'][r.start:r.end]\n",
    "        end = end - count_whitespaces(word)\n",
    "        temp_preds = [s]\n",
    "        try:\n",
    "            while d[1]['end'][s+1] <= end:\n",
    "                temp_preds.append(s+1)\n",
    "                s +=1\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        tmp = False\n",
    "        \n",
    "        if r.entity_type == 'PHONE_CUSTOM':\n",
    "            if date_check(word):\n",
    "                continue\n",
    "            for w in PHONE_ALLOW_LIST:\n",
    "                if w in d[1]['full_text'][max(r.start-50, 0):min(r.end+50, len(d[1]['full_text']))]:\n",
    "                    tmp = False\n",
    "                    break\n",
    "                else:\n",
    "                    tmp = True \n",
    "            label =  'PHONE_NUM'\n",
    "        if r.entity_type == 'PERSON':\n",
    "            if str(i).upper() in wikipedia:\n",
    "                tmp = True\n",
    "                break\n",
    "            label =  'NAME_STUDENT'\n",
    "        if r.entity_type == 'URL_CUSTOM':\n",
    "            for w in URL_DENY_LIST:\n",
    "                if w in word:\n",
    "                    tmp = True\n",
    "                    break\n",
    "            label = 'URL_PERSONAL'\n",
    "        if r.entity_type == 'EMAIL_ADDRESS' or r.entity_type == 'EMAIL_CUSTOM':\n",
    "            label = \"EMAIL\"\n",
    "        if r.entity_type == 'ADDRESS_CUSTOM':\n",
    "            label = 'STREET_ADDRESS'\n",
    "        if r.entity_type in ['US_SSN', 'US_ITIN', 'US_PASSPORT', 'US_BANK_NUMBER', 'ID_CUSTOM']:\n",
    "            label = 'ID_NUM'\n",
    "        if r.entity_type == 'USERNAME':\n",
    "            label =  'USERNAME'\n",
    "        if tmp:\n",
    "            continue\n",
    "        for p in temp_preds:\n",
    "            if len(pre_preds) > 0:\n",
    "                if pre_preds[-1]['rlabel'] == r.entity_type and ((p - pre_preds[-1]['token'])==1):\n",
    "                    label_f = \"I-\"+label\n",
    "                else:\n",
    "                    label_f = \"B-\"+label\n",
    "            else:\n",
    "                label_f = \"B-\"+label\n",
    "            pre_preds.append(({\n",
    "                    \"document\":d[1]['document'],\n",
    "                    \"token\":p,\n",
    "                    \"label\":label_f,\n",
    "                    \"rlabel\":r.entity_type\n",
    "                }))\n",
    "    preds.extend(pre_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T19:25:47.651482Z",
     "iopub.status.busy": "2024-02-12T19:25:47.650976Z",
     "iopub.status.idle": "2024-02-12T19:25:47.677108Z",
     "shell.execute_reply": "2024-02-12T19:25:47.676009Z",
     "shell.execute_reply.started": "2024-02-12T19:25:47.651451Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted_results = pd.DataFrame(preds).iloc[:,:-1].reset_index()\n",
    "predicted_results.columns = ['row_id','document', 'token', 'label']\n",
    "\n",
    "temp = val_x[['document']].join(val_y)\n",
    "dictionary = temp['labels'].apply(lambda x: {'indx': list(range(len(x))), 'vals': x})\n",
    "indices = dictionary.apply(lambda x: x['indx']).explode()\n",
    "values = dictionary.apply(lambda x: x['vals']).explode()\n",
    "\n",
    "ground_truth = pd.concat([indices, values], axis=1).reset_index()\n",
    "ground_truth['document'] = ground_truth['index'].apply(lambda x: temp['document'][x])\n",
    "ground_truth = ground_truth.drop(columns='index')\n",
    "ground_truth.columns = ['token', 'label', 'document']\n",
    "ground_truth = ground_truth[ground_truth['label'] != 'O']\n",
    "ground_truth = ground_truth.reset_index(names=['row_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.27905004240882103\n",
      "Recall: 0.8255959849435383\n",
      "F1-Score 0.20855784469096672\n",
      "FBeta Score: 0.7677601759188619\n"
     ]
    }
   ],
   "source": [
    "print(\"FBeta Score: \" + str(pii_fbeta_score(predicted_results, ground_truth, 5)))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7500999,
     "sourceId": 66653,
     "sourceType": "competition"
    },
    {
     "datasetId": 1975,
     "sourceId": 3392,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4962,
     "sourceId": 7524,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 13,
     "sourceId": 7651,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 591205,
     "sourceId": 1065529,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 159367535,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 163088908,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
